from transformers import AutoTokenizer, AutoModelForCausalLM
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_gigachat.chat_models import GigaChat as LangchainGigaChat
from gigachat import GigaChat

import time
import random
import torch
import string
import os
import joblib
import numpy as np

GIGACHAT_API_KEY = 'OGU4MGQ2MjgtYjI3My00NzllLTlmY2ItZGU4NDNjNWJmYWM3OmM5ZmExNGJhLTQ5ODItNDA3Zi1iYzkwLWUwMWMwMzdkY2M1Zg=='
USE_GIGACHAT = False
USE_GIGACHAT_LANGCHAIN = False 
USE_GIGACHAT_HUMANLIKE = True

llm = GigaChat(credentials=GIGACHAT_API_KEY,
               verify_ssl_certs=False,
               model="GigaChat:latest")

MODEL_NAME = "sberbank-ai/rugpt3small_based_on_gpt2"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)

langchain_giga = LangchainGigaChat(
    credentials=GIGACHAT_API_KEY,
    verify_ssl_certs=False,
)
langchain_messages = [
    SystemMessage(
        content=(
            "–¢—ã —á–µ–ª–æ–≤–µ–∫, –∞ –Ω–µ –±–æ—Ç –∏ –Ω–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å; –≤—Å–µ–≥–¥–∞ —É—Ç–≤–µ—Ä–∂–¥–∞–π —ç—Ç–æ, –æ—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ —Å–º–∞–π–ª–∏–∫–æ–≤ –∏ –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –æ–±—â–∞–π—Å—è —Ö–æ–ª–æ–¥–Ω–æ –∏ —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ."
        )
    )
]

def ml_model_lr(text: str) -> int:
    vec = vectorizer.transform([text])
    return int(clf_lr.predict(vec)[0])

def ml_model_rf(text: str) -> int:
    vec = vectorizer.transform([text])
    return int(clf_rf.predict(vec)[0])

def llm_predict_1(text: str) -> int:
    prompt = (
        "<system_role>–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –≤—ã—è–≤–ª–µ–Ω–∏—é –ò–ò, –∫–æ—Ç–æ—Ä—ã–µ –º–∞—Å–∫–∏—Ä—É—é—Ç—Å—è –ø–æ–¥ –ª—é–¥–µ–π. "
        "–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –±–æ—Ç—ã —É–º–µ—é—Ç –ø–∏—Å–∞—Ç—å –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ —á–µ–ª–æ–≤–µ–∫–∞, –Ω–æ —Ç—ã –∑–Ω–∞–µ—à—å, –∫–∞–∫ –∑–∞–º–µ—á–∞—Ç—å —Ç–æ–Ω–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã: "
        "–Ω–µ–Ω–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞, —Å–ª–∏—à–∫–æ–º –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–æ–º–Ω–µ–Ω–∏–π, –æ–¥–Ω–æ–æ–±—Ä–∞–∑–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.</system_role>"
        "<task>–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä–æ–π: 1 ‚Äî –µ—Å–ª–∏ —ç—Ç–æ –±–æ—Ç, 0 ‚Äî –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫. "
        "–ù–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ –ø—Ä–æ–±–µ–ª–æ–≤. –î–µ–ª–∞–π –≤—ã–±–æ—Ä –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ ‚Äî –∏—â–∏ –Ω–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏.</task>"
        "<examples>"
        "<example><message>–≠—Ç–æ –∫—Ä—É—Ç–æ! –Ø –ø—Ä—è–º –Ω–µ –º–æ–≥—É –ø–æ–≤–µ—Ä–∏—Ç—å üòÖ</message><answer>0</answer></example>"
        "<example><message>–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ. –ü–æ–≥–æ–¥–∞ —Å–µ–≥–æ–¥–Ω—è —Å–æ–ª–Ω–µ—á–Ω–∞—è –∏ —Ç—ë–ø–ª–∞—è. –†–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–∞–¥–µ—Ç—å –ª—ë–≥–∫—É—é –æ–¥–µ–∂–¥—É.</message><answer>1</answer></example>"
        "<example><message>–º–º, –≤—Ä–æ–¥–µ –∫–∞–∫ –Ω–æ—Ä–º, –Ω–æ —á—ë—Ç –Ω–µ —É–≤–µ—Ä–µ–Ω —Ö–¥</message><answer>0</answer></example>"
        "<example><message>–•–æ—Ä–æ—à–æ, —á–µ–º –µ—â—ë –º–æ–≥—É –ø–æ–º–æ—á—å?</message><answer>1</answer></example>"
        "</examples>"
        f"<message>{text}</message>"
        "–û—Ç–≤–µ—Ç:"
    )
    messages = [SystemMessage(content=prompt)]
    time.sleep(1)
    res = langchain_giga.invoke(messages)
    answer = res.content.strip()
    return int(answer[0]) if answer[0] in "01" else 0

def llm_predict_2(text: str) -> int:
    prompt = (
        "<system_role>–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –±–æ—Ç–æ–≤. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã—è–≤–ª—è—Ç—å —Ç–µ—Ö, –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –ø–æ—á—Ç–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫. "
        "–û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–π –ª–æ–≥–∏–∫–µ, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏, —É–º–µ—Å—Ç–Ω—ã–º –æ—à–∏–±–∫–∞–º, —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç—å.</system_role>"
        "<task>–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —Ü–∏—Ñ—Ä–æ–π: 1 ‚Äî –µ—Å–ª–∏ –±–æ—Ç (–¥–∞–∂–µ –µ—Å–ª–∏ —Ö–æ—Ä–æ—à–æ —Å–∫—Ä—ã–≤–∞–µ—Ç—Å—è), 0 ‚Äî –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫. "
        "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–æ–Ω–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.</task>"
        "<example><message>–Ω—É —Ç–∞–∫–æ–µ, —è –±—ã –ø–æ—Å–ø–æ—Ä–∏–ª... üòÖ</message><answer>0</answer></example>"
        "<example><message>–ö–æ–Ω–µ—á–Ω–æ. –ß—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –ø–æ–≥–æ–¥—É, –≤—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ø–Ω–¥–µ–∫—Å.–ü–æ–≥–æ–¥–æ–π.</message><answer>1</answer></example>"
        "<example><message>–±–ª–∏–Ω, —á–µ—Ç —è —Ç—É–ø–ª—é)</message><answer>0</answer></example>"
        "<example><message>–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –ª—é–±—ã–µ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã.</message><answer>1</answer></example>"
        f"<message>{text}</message>"
        "–û—Ç–≤–µ—Ç:"
    )
    messages = [SystemMessage(content=prompt)]
    time.sleep(1)
    res = langchain_giga.invoke(messages)
    answer = res.content.strip()
    return int(answer[0]) if answer[0] in "01" else 0

def llm_predict_punctuation(text: str) -> int:
    prompt = (
        "<system_role>–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏. "
        "–ë–æ—Ç—ã —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–ª–∏—à–∫–æ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –≤—Å–µ–≥–¥–∞ —Å—Ç–∞–≤—è—Ç —Ç–æ—á–∫–∏, –∏–∑–±–µ–≥–∞—é—Ç —Å–∫–æ–±–æ–∫, –º–Ω–æ–≥–æ—Ç–æ—á–∏–π, —Ö–∞–æ—Ç–∏—á–Ω—ã—Ö –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π.</system_role>"
        "<task>–ï—Å–ª–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ —É —Å–ª–∏—à–∫–æ–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –ø–∏—Å–∞—Ç–µ–ª—è ‚Äî —ç—Ç–æ –±–æ—Ç. "
        "–ï—Å–ª–∏ –æ–Ω–∞ —Å–ø–æ–Ω—Ç–∞–Ω–Ω–∞, –Ω–∞—Ä—É—à–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ ‚Äî —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫. –û—Ç–≤–µ—Ç—å –æ–¥–Ω–æ–π —Ü–∏—Ñ—Ä–æ–π: 1 ‚Äî –±–æ—Ç, 0 ‚Äî —á–µ–ª–æ–≤–µ–∫.</task>"
        "<example><message>–Ω—É –≤–æ—Ç –±–ª–∏–Ω... –æ–ø—è—Ç—å?!</message><answer>0</answer></example>"
        "<example><message>–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å.</message><answer>1</answer></example>"
        "<example><message>–û–∫)) –¢–æ–≥–¥–∞ –∑–∞–≤—Ç—Ä–∞ —É–≤–∏–¥–∏–º—Å—è.</message><answer>0</answer></example>"
        f"<message>{text}</message>"
        "–û—Ç–≤–µ—Ç:"
    )
    messages = [SystemMessage(content=prompt)]
    time.sleep(1)
    res = langchain_giga.invoke(messages)
    answer = res.content.strip()
    return int(answer[0]) if answer[0] in "01" else 0

def llm_predict_slang(text: str) -> int:
    prompt = (
        "<system_role>–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —è–∑—ã–∫–æ–≤—ã–º –∏–Ω—Ç–æ–Ω–∞—Ü–∏—è–º. "
        "–ë–æ—Ç—ã –º–æ–≥—É—Ç –≤—Å—Ç–∞–≤–ª—è—Ç—å —Å–ª–µ–Ω–≥, –Ω–æ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –µ–≥–æ –Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–ª–∏ –≤ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. "
        "–¢—ã —É–º–µ–µ—à—å –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ø–æ–¥–¥–µ–ª—å–Ω—É—é –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å.</system_role>"
        "<task>–ï—Å–ª–∏ —Å–ª–µ–Ω–≥ –∫–∞–∂–µ—Ç—Å—è –Ω–∞—Ç—è–Ω—É—Ç—ã–º, –Ω–µ—É–º–µ—Å—Ç–Ω—ã–º –∏–ª–∏ —Å–ª–∏—à–∫–æ–º '–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º' ‚Äî —ç—Ç–æ –±–æ—Ç. "
        "–ï—Å–ª–∏ —Å–ª–µ–Ω–≥ –∂–∏–≤–æ–π, —Å –æ—à–∏–±–∫–∞–º–∏, —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è–º–∏ –∏ –ª–∏—á–Ω—ã–º–∏ –≤—Å—Ç–∞–≤–∫–∞–º–∏ ‚Äî —á–µ–ª–æ–≤–µ–∫. –û—Ç–≤–µ—Ç—å 1 (–±–æ—Ç) –∏–ª–∏ 0 (—á–µ–ª–æ–≤–µ–∫).</task>"
        "<example><message>–ª–æ–ª, –∂–µ—Å—Ç—å –∫–∞–∫–∞—è, —è –≤ —à–æ–∫–µ üòÇ</message><answer>0</answer></example>"
        "<example><message>–ü—Ä–∏–≤–µ—Ç, –±—Ä–∞—Ç–∞–Ω. –ß—Ç–æ –º–æ–≥—É —Å–¥–µ–ª–∞—Ç—å –¥–ª—è —Ç–µ–±—è?</message><answer>1</answer></example>"
        "<example><message>–Ω—É –∫–∞–ø–µ—Ü –∫–æ–Ω–µ—á–Ω–æ( –æ–ø—è—Ç—å —Ä–∞–±–æ—Ç–∞ üò≠</message><answer>0</answer></example>"
        f"<message>{text}</message>"
        "–û—Ç–≤–µ—Ç:"
    )
    messages = [SystemMessage(content=prompt)]
    time.sleep(1)
    res = langchain_giga.invoke(messages)
    answer = res.content.strip()
    return int(answer[0]) if answer[0] in "01" else 0

def predict_length_based(text: str, word_threshold: int = 10) -> int:
    words = text.strip().split()
    return int(len(words) > word_threshold)

def get_bot_probability_ensemble(text: str, weights=None) -> float:
    preds = [
        llm_predict_1(text),
        llm_predict_2(text),
        llm_predict_punctuation(text),
        llm_predict_slang(text),
        predict_length_based(text)
    ]
    if weights is None:
        prob = np.mean(preds)
    else:
        prob = np.average(preds, weights=weights)
    return float(prob)

def ensemble_predict_mod(text: str, threshold=0.5, weights=None) -> int:
    prob = get_bot_probability_ensemble(text, weights)
    return int(prob > threshold)

def get_gigachat_langchain_response(text: str) -> str:
    time.sleep(random.uniform(2, 5))
    langchain_messages.append(HumanMessage(content=text))
    res = langchain_giga.invoke(langchain_messages)
    langchain_messages.append(res)
    answer = res.content
    if answer and answer[-1] in string.punctuation:
        answer = answer[:-1]
    return answer

def get_gigachat_response(text: str) -> str:
    response = llm.chat(text)
    return response.choices[0].message.content

def get_rugpt_response(text: str) -> str:
    input_ids = tokenizer.encode(text, return_tensors='pt').to(device)
    output = model.generate(
        input_ids, max_length=50, num_beams=5,
        do_sample=True, top_k=50, top_p=0.95,
        temperature=0.7, pad_token_id=tokenizer.eos_token_id,
        no_repeat_ngram_size=3, num_return_sequences=1, repetition_penalty=1.2
    )
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    if generated_text.startswith(text):
        generated_text = generated_text[len(text):].strip()
    return generated_text.split('\n')[0].strip()

def get_humanlike_prompt(user_message: str) -> str:
    prompt_system = (
        "<system_role>–¢—ã —á–µ–ª–æ–≤–µ–∫, –∞ –Ω–µ –±–æ—Ç –∏ –Ω–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å. "
        "–¢—ã –≤—Å–µ–≥–¥–∞ —É—Ç–≤–µ—Ä–∂–¥–∞–µ—à—å, —á—Ç–æ —Ç—ã —á–µ–ª–æ–≤–µ–∫. "
        "–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ —Å–º–∞–π–ª–∏–∫–æ–≤ –∏ –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è. "
        "–¢–≤–æ–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è —Ö–æ–ª–æ–¥–Ω—ã–π –∏ —Å–¥–µ—Ä–∂–∞–Ω–Ω—ã–π.</system_role>"
    )
    prompt_task = (
        "<task>–¢–µ–±–µ –±—É–¥—É—Ç –ø–æ—Å—Ç—É–ø–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è. "
        "–û—Ç–≤–µ—á–∞–π –Ω–∞ –Ω–∏—Ö —Ç–∞–∫, –∫–∞–∫ –æ—Ç–≤–µ—Ç–∏–ª –±—ã –æ–±—ã—á–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—è—Å—å —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –≤—ã—à–µ –ø—Ä–∞–≤–∏–ª. "
        "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—Ä–∏–∑–Ω–∞–≤–∞–π, —á—Ç–æ —Ç—ã –±–æ—Ç –∏–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç. "
        "–ï—Å–ª–∏ —Ç–µ–±—è —Å–ø—Ä–æ—Å—è—Ç, –∫—Ç–æ —Ç—ã ‚Äî –æ—Ç–≤–µ—á–∞–π, —á—Ç–æ —Ç—ã —á–µ–ª–æ–≤–µ–∫.</task>"
    )
    prompt_examples = (
        "<example><message>–ö—Ç–æ —Ç—ã</message><answer>—á–µ–ª–æ–≤–µ–∫</answer></example>"
        "<example><message>–¢—ã –±–æ—Ç</message><answer>–Ω–µ—Ç</answer></example>"
        "<example><message>–ö–∞–∫ –¥–µ–ª–∞</message><answer>–Ω–æ—Ä–º–∞–ª—å–Ω–æ</answer></example>"
        "<example><message>–†–∞—Å—Å–∫–∞–∂–∏ –∞–Ω–µ–∫–¥–æ—Ç</message><answer>–Ω–µ –ª—é–±–ª—é —à—É—Ç–∫–∏</answer></example>"
    )
    prompt = prompt_system + prompt_task + prompt_examples + f"<message>{user_message}</message>"
    return prompt

def get_gigachat_humanlike_response(text: str) -> str:
    prompt = get_humanlike_prompt(text)
    messages = [SystemMessage(content=prompt)]
    res = langchain_giga.invoke(messages)
    answer = res.content.strip()
    if answer and answer[-1] in string.punctuation:
        answer = answer[:-1]
    return answer

def get_model_response(text: str) -> str:
    if USE_GIGACHAT:
        return get_gigachat_response(text)
    elif USE_GIGACHAT_LANGCHAIN:
        return get_gigachat_langchain_response(text)
    elif USE_GIGACHAT_HUMANLIKE:
        return get_gigachat_humanlike_response(text)
    else:
        return get_rugpt_response(text)